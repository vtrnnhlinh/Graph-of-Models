{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from rapidfuzz import fuzz\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ------------------------\n",
    "# Step 1: Load datasets\n",
    "# ------------------------\n",
    "df1 = pd.read_parquet(\"../datasets/dataset_1.parquet\")\n",
    "df2 = pd.read_parquet(\"../datasets/dataset_2.parquet\")\n",
    "df3 = pd.read_parquet(\"../datasets/dataset_3.parquet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize_ingredient(s):\n",
    "    return s.strip().lower()\n",
    "\n",
    "def extract_unique_ingredients(df):\n",
    "    ingredients = set()\n",
    "    for row in df[\"ingredients\"].dropna():\n",
    "        if isinstance(row, str):\n",
    "            items = row.split(',')\n",
    "        elif isinstance(row, (list, np.ndarray, tuple)):\n",
    "            items = row\n",
    "        else:\n",
    "            continue\n",
    "        for ing in items:\n",
    "            if isinstance(ing, str):\n",
    "                ingredients.add(normalize_ingredient(ing))\n",
    "    return ingredients\n",
    "def build_canonical_map(ingredients_list, threshold=85):\n",
    "    \"\"\"Fast fuzzy canonical map with early stopping and improved matching.\"\"\"\n",
    "    ingredients = sorted(set(ingredients_list), key=len)  # sort for early matching\n",
    "    canonical = []\n",
    "    mapping = {}\n",
    "\n",
    "    @lru_cache(maxsize=None)  # cache repeated calls to speed up fuzzy ratio\n",
    "    def cached_ratio(a, b):\n",
    "        return fuzz.token_sort_ratio(a, b)\n",
    "\n",
    "    print(\"âš¡ Optimized fuzzy canonical map building...\")\n",
    "    for ing in tqdm(ingredients, desc=\"Fuzzy matching\", unit=\"ingredient\"):\n",
    "        match_found = False\n",
    "        for canon in canonical:\n",
    "            score = cached_ratio(ing, canon)\n",
    "            if score >= threshold:\n",
    "                mapping[ing] = canon\n",
    "                match_found = True\n",
    "                break\n",
    "        if not match_found:\n",
    "            canonical.append(ing)\n",
    "            mapping[ing] = ing\n",
    "\n",
    "    return mapping\n",
    "\n",
    "def canonicalize_set(ingredient_set, mapping):\n",
    "    return {mapping.get(ing, ing) for ing in ingredient_set}\n",
    "\n",
    "def jaccard_index(a, b):\n",
    "    return len(a & b) / len(a | b) if (a | b) else 0.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[10]\u001b[39m\u001b[32m, line 9\u001b[39m\n\u001b[32m      6\u001b[39m all_ingredients = \u001b[38;5;28mlist\u001b[39m(set1_raw | set2_raw | set3_raw)\n\u001b[32m      8\u001b[39m \u001b[38;5;66;03m# Build fast fuzzy map\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m9\u001b[39m canonical_map = \u001b[43mbuild_canonical_map\u001b[49m\u001b[43m(\u001b[49m\u001b[43mall_ingredients\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mthreshold\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m85\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m     11\u001b[39m \u001b[38;5;66;03m# Apply canonical map\u001b[39;00m\n\u001b[32m     12\u001b[39m canon1 = canonicalize_set(set1_raw, canonical_map)\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[9]\u001b[39m\u001b[32m, line 25\u001b[39m, in \u001b[36mbuild_canonical_map\u001b[39m\u001b[34m(ingredients_list, threshold)\u001b[39m\n\u001b[32m     23\u001b[39m match_found = \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[32m     24\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m canon \u001b[38;5;129;01min\u001b[39;00m canonical:\n\u001b[32m---> \u001b[39m\u001b[32m25\u001b[39m     score = \u001b[43mfuzz\u001b[49m\u001b[43m.\u001b[49m\u001b[43mratio\u001b[49m\u001b[43m(\u001b[49m\u001b[43ming\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcanon\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     26\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m score >= threshold:\n\u001b[32m     27\u001b[39m         mapping[ing] = canon\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "# Extract all ingredients across datasets\n",
    "set1_raw = extract_unique_ingredients(df1)\n",
    "set2_raw = extract_unique_ingredients(df2)\n",
    "set3_raw = extract_unique_ingredients(df3)\n",
    "\n",
    "all_ingredients = list(set1_raw | set2_raw | set3_raw)\n",
    "\n",
    "# Build fast fuzzy map\n",
    "canonical_map = build_canonical_map(all_ingredients, threshold=85)\n",
    "\n",
    "# Apply canonical map\n",
    "canon1 = canonicalize_set(set1_raw, canonical_map)\n",
    "canon2 = canonicalize_set(set2_raw, canonical_map)\n",
    "canon3 = canonicalize_set(set3_raw, canonical_map)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "datasets = {\n",
    "    \"dataset_1\": canon1,\n",
    "    \"dataset_2\": canon2,\n",
    "    \"dataset_3\": canon3,\n",
    "}\n",
    "\n",
    "names = list(datasets.keys())\n",
    "results = pd.DataFrame(index=names, columns=names, dtype=float)\n",
    "\n",
    "for i in names:\n",
    "    for j in names:\n",
    "        if i == j:\n",
    "            results.loc[i, j] = 1.0\n",
    "        else:\n",
    "            results.loc[i, j] = round(jaccard_index(datasets[i], datasets[j]), 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ------------------------\n",
    "# Step 5: Save result\n",
    "# ------------------------\n",
    "\n",
    "output_dir = \"./results\"\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "results.to_csv(os.path.join(output_dir, \"jaccard_index_matrix.csv\"))\n",
    "print(results)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Graph-of-Models",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
